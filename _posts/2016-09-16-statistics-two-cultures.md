---
layout: post
title: Two Cultures of Statistical Learning and What Science is About
date: 2016-09-16
sources: "On Chomsky and the Two Cultures of Statistical Learning" "The End of Theory: The Data Deluge Makes the Scientific Method Obsolute" "50 years of Data Science" "Data Science and its Relationship to Big Data and Data-Driven Decision Making"
type: thoughts
---

Over the past two days, the readings from two of my courses mentioned the same concept -- "Two Cultures of Statistical Learning". The papers that explicitly mentioned the "Two Cultures" idea gave the following distinction: one culture, the "data modeling culture", focuses on inferring the underlying models that determine the results we observe; the other, "algorithmic modeling culture", focuses on predicting the responses that we actually see. To varying extents, all four readings seemed to lean towards the same side (the algorithmic/predictive side). I guess that's not too surprising, since the readings came from classes that emphasize computational methods. 

The [most extreme article](https://www.wired.com/2008/06/pb-theory/) (though it does not explicitly mention the Two Cultures idea) heavily emphasizes the predictive culture. Citing Peter Norvig's statement that "All models are wrong, and increasingly you can succeed without them", this article argues that huge amounts of data render the scientific method's modeling culture obsolete. 

It's cool that this article cites Peter Norvig, because he wrote the [reading](http://norvig.com/chomsky.html) in which I first came across the "Two Cultures" idea. His article mentioned an interesting point -- whether predictive models count as science. He points out that the "science" papers published do mostly deal with accurately predicting what happens, and contain a smaller emphasis on finding underlying insights. He captures the difference between the two cultures with quotes from two physicists: "Physics can progress without the proofs, but we can't go on without the facts." and "All science is either physics or stamp collecting."

These two quotes each support a different one of the Two Cultures, but they don't seem exactly exclusive. The first says that facts are *necessary* for science, and the second argues that the facts don't count as *actual* science. This seems to fit with an idea from another [article](http://online.liebertpub.com/doi/pdf/10.1089/big.2013.1508), which identifies a challenge in defining a field -- the "natural tendency to associate what a practitioner does with the definition of the practitioner's field". It also uses an analogy from the physical sciences, describing the work of lab technicians as what (especially entry-level) chemists mostly do, but noting that this isn't what the *field* of chemistry is mostly about. So maybe the facts that support physics research are prerequisites, the things that most physicists spend most of their time doing, and, accordingly, the things that occupy the most space in publications (though publications should put more focus on the actual science parts, I think, but maybe this is the same concept at a different level), but without the insights they're just "stamp collecting", not "true" science. But as this article notes, with chemistry and with data science, most people *do* have to spend most of their time on the prerequisite stuff.

If that view is true, then the extreme article that I first mentioned isn't exactly correct -- predictive models, though very important, don't render insight-driven models obsolete. Facts are essential to physics and technical lab work is essential to chemistry -- without them, it might be impossible to even get to the level of actual science (or at least, discovering scientific insights without starting from the facts upwards seems like an unreliable process). So solely focusing on the "stamp collecting" part creates more usable output than the opposite. But even though this producse output, it seems to miss the point. The point of technical lab work is to actually get to the chemistry part, not to do technical lab work for the sake of technical lab work.

Just based on gut feeling, the statistical culture of predicting *what* happens seems like the fact-finding idea, and the culture of figuring out the *why* it happens seems more like the finding insights idea. If that's true, then huge amounts of data and predictive power don't render the scientific method of hypotheses and models and understanding **why** obsolete. On the contrary, it would just serve as a more effective means of getting to the original goal -- finding insights and explanations. Conveniently, figuring out underlying explanations also seems a lot more inspirational and exciting than merely trying to predict what will happen.
